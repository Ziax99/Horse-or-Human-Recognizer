{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Horse_or_Human_transferLearning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbFmQdsZs5eW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import all the necessary files!\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "outputId": "7d754f98-1c6d-4c8d-b1cb-2b6ff48f5a6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3),\n",
        "                                include_top = False, #Because first layer in inception model is flatten layer(we don't need it)\n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "# Print the model summary\n",
        "pre_trained_model.summary()\n",
        "\n",
        "# Expected Output is extremely large, but should end with:\n",
        "\n",
        "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
        "#                                                                 activation_276[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
        "#                                                                 activation_280[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
        "#                                                                 mixed9_1[0][0]                   \n",
        "#                                                                 concatenate_5[0][0]              \n",
        "#                                                                 activation_281[0][0]             \n",
        "#==================================================================================================\n",
        "#Total params: 21,802,784\n",
        "#Trainable params: 0\n",
        "#Non-trainable params: 21,802,784"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-08-22 20:22:51--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.132.128, 2607:f8b0:4001:c07::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.132.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M   140MB/s    in 0.6s    \n",
            "\n",
            "2019-08-22 20:22:52 (140 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0822 20:22:53.121469 140619400501120 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFsUlwdfs_wg",
        "colab_type": "code",
        "outputId": "dc3a5a08-59b9-4861-8801-6eb00e2abe80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "# Expected Output:\n",
        "# ('last layer output shape: ', (None, 7, 7, 768))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "last layer output shape:  (None, 7, 7, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bsWZWp5oMq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "outputId": "5d977a08-29b6-4e03-80ac-b6c4333382a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model( pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['acc'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Expected output will be large. Last few lines should be:\n",
        "\n",
        "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
        "#                                                                  activation_251[0][0]             \n",
        "#                                                                  activation_256[0][0]             \n",
        "#                                                                  activation_257[0][0]             \n",
        "# __________________________________________________________________________________________________\n",
        "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
        "# __________________________________________________________________________________________________\n",
        "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
        "# ==================================================================================================\n",
        "# Total params: 47,512,481\n",
        "# Trainable params: 38,537,217\n",
        "# Non-trainable params: 8,975,264\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0822 20:23:04.738113 140619400501120 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         38536192    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            1025        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrnL_IQ8knWA",
        "colab_type": "code",
        "outputId": "dcaebff2-d561-4755-fa3e-18010219a2d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "# Get the Horse or Human dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human Validation dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
        "  \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/training')\n",
        "zip_ref.close()\n",
        "\n",
        "local_zip = '//tmp/validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation')\n",
        "zip_ref.close()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-08-22 20:23:05--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.195.128, 2607:f8b0:4001:c07::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.195.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘/tmp/horse-or-human.zip’\n",
            "\n",
            "/tmp/horse-or-human 100%[===================>] 142.65M   191MB/s    in 0.7s    \n",
            "\n",
            "2019-08-22 20:23:06 (191 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2019-08-22 20:23:07--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.195.128, 2607:f8b0:4001:c07::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.195.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
            "\n",
            "/tmp/validation-hor 100%[===================>]  10.95M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2019-08-22 20:23:07 (136 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9okX7_ovskI",
        "colab_type": "code",
        "outputId": "d59387c2-7ea6-4c5e-a0b3-d30927a63191",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "train_horses_dir = os.path.join(train_dir, 'horses') # Directory with our training horse pictures\n",
        "train_humans_dir = os.path.join(train_dir, 'humans') # Directory with our training humans pictures\n",
        "validation_horses_dir = os.path.join(validation_dir, 'horses') # Directory with our validation horse pictures\n",
        "validation_humans_dir = os.path.join(validation_dir, 'humans')# Directory with our validation humanas pictures\n",
        "\n",
        "train_horses_fnames = os.listdir(train_horses_dir)\n",
        "train_humans_fnames = os.listdir(train_humans_dir)\n",
        "validation_horses_fnames = os.listdir(validation_horses_dir)\n",
        "validation_humans_fnames = os.listdir(validation_humans_dir)\n",
        "\n",
        "print(len(train_horses_fnames))\n",
        "print(len(train_humans_fnames))\n",
        "print(len(validation_horses_fnames))\n",
        "print(len(validation_humans_fnames))\n",
        "\n",
        "# Expected Output:\n",
        "# 500\n",
        "# 527\n",
        "# 128\n",
        "# 128"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "527\n",
            "128\n",
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "ab014b65-db90-4504-d2db-d16e27f0cfdb"
      },
      "source": [
        "# Define our example directories and files\n",
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'binary', \n",
        "                                                    target_size = (150, 150))     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
        "                                                          batch_size  = 20,\n",
        "                                                          class_mode  = 'binary', \n",
        "                                                          target_size = (150, 150))\n",
        "\n",
        "# Expected Output:\n",
        "# Found 1027 images belonging to 2 classes.\n",
        "# Found 256 images belonging to 2 classes."
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bdd88d6e-5964-45db-d683-be61e447bbcf"
      },
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "# (It should take less than 100 epochs)\n",
        "callbacks = myCallback()\n",
        "history = model.fit_generator(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = 100,\n",
        "            epochs = 100,\n",
        "            validation_steps = 50,\n",
        "            verbose = 2,\n",
        "            callbacks=[callbacks])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "100/100 - 29s - loss: 0.1667 - acc: 0.9381 - val_loss: 0.0068 - val_acc: 1.0000\n",
            "Epoch 2/100\n",
            "100/100 - 23s - loss: 0.0605 - acc: 0.9801 - val_loss: 0.0618 - val_acc: 0.9808\n",
            "Epoch 3/100\n",
            "100/100 - 23s - loss: 0.0532 - acc: 0.9824 - val_loss: 0.0309 - val_acc: 0.9960\n",
            "Epoch 4/100\n",
            "100/100 - 22s - loss: 0.0531 - acc: 0.9816 - val_loss: 0.0379 - val_acc: 0.9919\n",
            "Epoch 5/100\n",
            "100/100 - 22s - loss: 0.0345 - acc: 0.9873 - val_loss: 0.0710 - val_acc: 0.9889\n",
            "Epoch 6/100\n",
            "100/100 - 23s - loss: 0.0293 - acc: 0.9874 - val_loss: 0.1352 - val_acc: 0.9686\n",
            "Epoch 7/100\n",
            "100/100 - 22s - loss: 0.0459 - acc: 0.9837 - val_loss: 0.3460 - val_acc: 0.9514\n",
            "Epoch 8/100\n",
            "100/100 - 22s - loss: 0.0331 - acc: 0.9914 - val_loss: 0.4131 - val_acc: 0.9484\n",
            "Epoch 9/100\n",
            "100/100 - 22s - loss: 0.0484 - acc: 0.9918 - val_loss: 0.0533 - val_acc: 0.9919\n",
            "Epoch 10/100\n",
            "100/100 - 22s - loss: 0.0389 - acc: 0.9884 - val_loss: 0.0777 - val_acc: 0.9879\n",
            "Epoch 11/100\n",
            "100/100 - 22s - loss: 0.0416 - acc: 0.9878 - val_loss: 0.2252 - val_acc: 0.9686\n",
            "Epoch 12/100\n",
            "100/100 - 22s - loss: 0.0275 - acc: 0.9924 - val_loss: 0.4537 - val_acc: 0.9555\n",
            "Epoch 13/100\n",
            "100/100 - 22s - loss: 0.0214 - acc: 0.9924 - val_loss: 0.2394 - val_acc: 0.9565\n",
            "Epoch 14/100\n",
            "100/100 - 22s - loss: 0.0203 - acc: 0.9929 - val_loss: 0.2990 - val_acc: 0.9696\n",
            "Epoch 15/100\n",
            "100/100 - 23s - loss: 0.0173 - acc: 0.9959 - val_loss: 0.3078 - val_acc: 0.9646\n",
            "Epoch 16/100\n",
            "100/100 - 23s - loss: 0.0103 - acc: 0.9960 - val_loss: 0.6381 - val_acc: 0.9494\n",
            "Epoch 17/100\n",
            "100/100 - 22s - loss: 0.0173 - acc: 0.9954 - val_loss: 0.2951 - val_acc: 0.9605\n",
            "Epoch 18/100\n",
            "100/100 - 22s - loss: 0.0303 - acc: 0.9914 - val_loss: 0.4777 - val_acc: 0.9605\n",
            "Epoch 19/100\n",
            "100/100 - 23s - loss: 0.0173 - acc: 0.9935 - val_loss: 0.3530 - val_acc: 0.9676\n",
            "Epoch 20/100\n",
            "100/100 - 23s - loss: 0.0191 - acc: 0.9934 - val_loss: 0.6108 - val_acc: 0.9524\n",
            "Epoch 21/100\n",
            "100/100 - 22s - loss: 0.0245 - acc: 0.9924 - val_loss: 0.5259 - val_acc: 0.9524\n",
            "Epoch 22/100\n",
            "100/100 - 23s - loss: 0.0115 - acc: 0.9975 - val_loss: 0.9510 - val_acc: 0.9443\n",
            "Epoch 23/100\n",
            "100/100 - 23s - loss: 0.0137 - acc: 0.9950 - val_loss: 0.3576 - val_acc: 0.9636\n",
            "Epoch 24/100\n",
            "100/100 - 23s - loss: 0.0082 - acc: 0.9970 - val_loss: 0.2892 - val_acc: 0.9666\n",
            "Epoch 25/100\n",
            "100/100 - 23s - loss: 0.0126 - acc: 0.9970 - val_loss: 0.3537 - val_acc: 0.9605\n",
            "Epoch 26/100\n",
            "100/100 - 23s - loss: 0.0333 - acc: 0.9934 - val_loss: 0.4266 - val_acc: 0.9565\n",
            "Epoch 27/100\n",
            "100/100 - 22s - loss: 0.0133 - acc: 0.9975 - val_loss: 0.5156 - val_acc: 0.9575\n",
            "Epoch 28/100\n",
            "100/100 - 24s - loss: 0.0152 - acc: 0.9939 - val_loss: 0.3674 - val_acc: 0.9696\n",
            "Epoch 29/100\n",
            "100/100 - 24s - loss: 0.0375 - acc: 0.9909 - val_loss: 0.7221 - val_acc: 0.9545\n",
            "Epoch 30/100\n",
            "100/100 - 23s - loss: 0.0192 - acc: 0.9949 - val_loss: 0.9242 - val_acc: 0.9524\n",
            "Epoch 31/100\n",
            "100/100 - 23s - loss: 0.0263 - acc: 0.9949 - val_loss: 1.0107 - val_acc: 0.9453\n",
            "Epoch 32/100\n",
            "100/100 - 23s - loss: 0.0126 - acc: 0.9965 - val_loss: 1.2906 - val_acc: 0.9372\n",
            "Epoch 33/100\n",
            "100/100 - 23s - loss: 0.0106 - acc: 0.9969 - val_loss: 0.7760 - val_acc: 0.9474\n",
            "Epoch 34/100\n",
            "100/100 - 23s - loss: 0.0049 - acc: 0.9970 - val_loss: 0.4136 - val_acc: 0.9686\n",
            "Epoch 35/100\n",
            "100/100 - 23s - loss: 0.0067 - acc: 0.9975 - val_loss: 0.4314 - val_acc: 0.9676\n",
            "Epoch 36/100\n",
            "100/100 - 23s - loss: 0.0145 - acc: 0.9970 - val_loss: 0.1859 - val_acc: 0.9848\n",
            "Epoch 37/100\n",
            "100/100 - 23s - loss: 0.0097 - acc: 0.9954 - val_loss: 0.1874 - val_acc: 0.9838\n",
            "Epoch 38/100\n",
            "100/100 - 23s - loss: 0.0092 - acc: 0.9985 - val_loss: 0.3351 - val_acc: 0.9686\n",
            "Epoch 39/100\n",
            "100/100 - 23s - loss: 0.0092 - acc: 0.9965 - val_loss: 0.3547 - val_acc: 0.9737\n",
            "Epoch 40/100\n",
            "100/100 - 22s - loss: 0.0168 - acc: 0.9965 - val_loss: 0.2033 - val_acc: 0.9879\n",
            "Epoch 41/100\n",
            "100/100 - 24s - loss: 0.0135 - acc: 0.9975 - val_loss: 0.3950 - val_acc: 0.9656\n",
            "Epoch 42/100\n",
            "100/100 - 23s - loss: 0.0132 - acc: 0.9954 - val_loss: 0.2983 - val_acc: 0.9727\n",
            "Epoch 43/100\n",
            "100/100 - 23s - loss: 0.0119 - acc: 0.9965 - val_loss: 0.3430 - val_acc: 0.9666\n",
            "Epoch 44/100\n",
            "100/100 - 23s - loss: 0.0157 - acc: 0.9959 - val_loss: 0.4185 - val_acc: 0.9605\n",
            "Epoch 45/100\n",
            "100/100 - 23s - loss: 0.0119 - acc: 0.9975 - val_loss: 0.2542 - val_acc: 0.9879\n",
            "Epoch 46/100\n",
            "100/100 - 23s - loss: 0.0050 - acc: 0.9975 - val_loss: 0.6674 - val_acc: 0.9514\n",
            "Epoch 47/100\n",
            "100/100 - 23s - loss: 0.0174 - acc: 0.9975 - val_loss: 0.7210 - val_acc: 0.9504\n",
            "Epoch 48/100\n",
            "100/100 - 23s - loss: 0.0161 - acc: 0.9960 - val_loss: 0.7400 - val_acc: 0.9484\n",
            "Epoch 49/100\n",
            "100/100 - 23s - loss: 0.0139 - acc: 0.9970 - val_loss: 1.6473 - val_acc: 0.9383\n",
            "Epoch 50/100\n",
            "100/100 - 23s - loss: 0.0032 - acc: 0.9985 - val_loss: 0.5486 - val_acc: 0.9494\n",
            "Epoch 51/100\n",
            "100/100 - 23s - loss: 0.0137 - acc: 0.9959 - val_loss: 0.9489 - val_acc: 0.9474\n",
            "Epoch 52/100\n",
            "100/100 - 23s - loss: 0.0218 - acc: 0.9959 - val_loss: 0.6850 - val_acc: 0.9474\n",
            "Epoch 53/100\n",
            "100/100 - 22s - loss: 0.0073 - acc: 0.9985 - val_loss: 1.0256 - val_acc: 0.9484\n",
            "Epoch 54/100\n",
            "\n",
            "Reached 99.9% accuracy so cancelling training!\n",
            "100/100 - 24s - loss: 0.0032 - acc: 0.9995 - val_loss: 1.0353 - val_acc: 0.9474\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "b53c9bfd-c7f0-4a36-ad13-af32a9272c37"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}